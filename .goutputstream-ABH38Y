

import argparse
import math
# import h5py
import numpy as np
import scipy as sp
import google.protobuf
import tensorflow as tf
import socket
import importlib
import os
import sys
import helper_VisualSFM_Kings
from multiprocessing import Pool

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
sys.path.append(BASE_DIR)
sys.path.append(os.path.join(BASE_DIR, 'models'))
sys.path.append(os.path.join(BASE_DIR, 'utils'))
# import provider
# import helper
# import helper_VisualSFM_7scene
# import helper_kings
# import tf_util

#dataset_train = 'dataset_train.txt' 
#dataset_train = 'dataset_new_train.txt'
dataset_train = 'dataset_new_train3D.txt'
DataSetSize = 52000 
DataSetSize = 49972 
#dataset_train = 'dataset_new_test3D.txt'
#DataSetSize = 3962 
#ataset_train = 'dataset_new_evaluate.txt'

parser = argparse.ArgumentParser()
parser.add_argument('--gpu', type=int, default=0, help='GPU to use [default: GPU 0]')
parser.add_argument('--model', default='pointnet_pose', help='Model name: pointnet_pose or pointnet_cls_basic [default: pointnet_pose]')
parser.add_argument('--log_dir', default='log', help='Log dir [default: log]')
parser.add_argument('--num_point', type=int, default=1024, help='Point Number [256/512/1024/2048] [default: 1024]')
parser.add_argument('--max_epoch', type=int, default=2000, help='Epoch to run [default: 250]')
parser.add_argument('--batch_size', type=int, default=300, help='Batch Size during training [default: 32]')
parser.add_argument('--learning_rate', type=float, default=0.001, help='Initial learning rate [default: 0.001]')
parser.add_argument('--momentum', type=float, default=0.9, help='Initial learning rate [default: 0.9]')
parser.add_argument('--model_path', default='log/model.ckpt', help='model checkpoint file path [default: log/model.ckpt]') 
parser.add_argument('--optimizer', default='adam', help='adam or momentum [default: adam]')
parser.add_argument('--decay_step', type=int, default=200000, help='Decay step for lr decay [default: 200000]')
parser.add_argument('--decay_rate', type=float, default=0.8, help='Decay rate for lr decay [default: 0.8]')
FLAGS = parser.parse_args()


BATCH_SIZE = FLAGS.batch_size
NUM_POINT = FLAGS.num_point
MAX_EPOCH = FLAGS.max_epoch
BASE_LEARNING_RATE = FLAGS.learning_rate
GPU_INDEX = FLAGS.gpu
MOMENTUM = FLAGS.momentum
OPTIMIZER = FLAGS.optimizer
DECAY_STEP = FLAGS.decay_step
DECAY_RATE = FLAGS.decay_rate
MODEL_PATH = FLAGS.model_path

BLOCK_SIZE1 = 16 # sqrt(NUM_POINT / POOL_SIZE)
BLOCK_SIZE2 = 16 # sqrt(NUM_POINT / POOL_SIZE)



MIN_NUM_POINT = 150

NUM_POINT = BLOCK_SIZE1 * BLOCK_SIZE2

IMZ_SZ1 = 320 
IMZ_SZ2 = 240

MODEL = importlib.import_module(FLAGS.model) # import network module
MODEL_FILE = os.path.join(BASE_DIR, 'models', FLAGS.model+'.py')
LOG_DIR = FLAGS.log_dir
if not os.path.exists(LOG_DIR): os.mkdir(LOG_DIR)
os.system('cp %s %s' % (MODEL_FILE, LOG_DIR)) # bkp of model def
os.system('cp train.py %s' % (LOG_DIR)) # bkp of train procedure
LOG_FOUT = open(os.path.join(LOG_DIR, 'log_train.txt'), 'w')
LOG_FOUT.write(str(FLAGS)+'\n')

MAX_NUM_POINT = NUM_POINT
# NUM_CLASSES = 40

BN_INIT_DECAY = 0.5
BN_DECAY_DECAY_RATE = 0.5
BN_DECAY_DECAY_STEP = float(DECAY_STEP)
BN_DECAY_CLIP = 0.99

HOSTNAME = socket.gethostname()

# ModelNet40 official train/test split
#TRAIN_FILES = provider.getDataFiles( \
#    os.path.join(BASE_DIR, 'data/modelnet40_ply_hdf5_2048/train_files.txt'))
#TEST_FILES = provider.getDataFiles(\
#    os.path.join(BASE_DIR, 'data/modelnet40_ply_hdf5_2048/test_files.txt'))

def log_string(out_str):
    LOG_FOUT.write(out_str+'\n')
    LOG_FOUT.flush()
    print(out_str)

def get_learning_rate(batch):
    learning_rate = tf.train.exponential_decay(
                        BASE_LEARNING_RATE,  # Base learning rate.
                        batch * BATCH_SIZE,  # Current index into the dataset.
                        DECAY_STEP,          # Decay step.
                        DECAY_RATE,          # Decay rate.
                        staircase=True)
    learing_rate = tf.maximum(learning_rate, 0.00001) # CLIP THE LEARNING RATE!
    return learning_rate        

def get_bn_decay(batch):
    bn_momentum = tf.train.exponential_decay(
                      BN_INIT_DECAY,
                      batch*BATCH_SIZE,
                      BN_DECAY_DECAY_STEP,
                      BN_DECAY_DECAY_RATE,
                      staircase=True)
    bn_decay = tf.minimum(BN_DECAY_CLIP, 1 - bn_momentum)
    return bn_decay

def add_noise(images_des):
	all_des = images_des.astype(float)+np.multiply(5.0, np.random.randn(images_des.shape[0], 128))  
	np.clip(all_des, 0.0, 255.0) 
	return all_des 


def train():
    with tf.Graph().as_default():
        with tf.device('/gpu:'+str(GPU_INDEX)):

            # images_train, poses_train = helper.getKings() 
		is_training_pl = tf.placeholder(tf.bool, shape=())
		point_set, pointclouds_3d, pose_set = MODEL.placeholder_inputs(BATCH_SIZE, BLOCK_SIZE1, BLOCK_SIZE2) 
		#print is_training_pl

		# Note the global_step=batch parameter to minimize. 
		# That tells the optimizer to helpfully increment the 'batch' parameter for you every time it trains.
		batch = tf.Variable(0)
		bn_decay = get_bn_decay(batch)
		tf.summary.scalar('bn_decay', bn_decay)

		sigx = tf.Variable(0.0)
		sigy = tf.Variable(-3.0)
		#print point_set.shape
		pred, pixel_points = MODEL.get_model(point_set, is_training_pl, bn_decay=bn_decay)
		# print pred.shape, pose_set.shape, pointclouds_3d.shape, pixel_points.shape
		loss = MODEL.get_loss(pred, pose_set, pointclouds_3d, pixel_points, sigx, sigy)
		tf.summary.scalar('loss', loss)

		#correct = tf.equal(tf.argmax(pred, 1), tf.to_int64(labels_pl))
		#accuracy = tf.reduce_sum(tf.cast(correct, tf.float32)) / float(BATCH_SIZE)
		# tf.summary.scalar('accuracy', accuracy)

		# Get training operator
		learning_rate = get_learning_rate(batch)

		tf.summary.scalar('learning_rate', learning_rate)
		if OPTIMIZER == 'momentum':
		    optimizer = tf.train.MomentumOptimizer(learning_rate, momentum=MOMENTUM)
		elif OPTIMIZER == 'adam':
		    optimizer = tf.train.AdamOptimizer(learning_rate)
		train_op = optimizer.minimize(loss, global_step=batch)

		# Add ops to save and restore all the variables.
		saver = tf.train.Saver()

		# Create a session
        config = tf.ConfigProto()
        config.gpu_options.allow_growth = True
        config.allow_soft_placement = True
        config.log_device_placement = False
        sess = tf.Session(config=config)
	#sess = tf.Session(config=tf.ConfigProto(
  	#	intra_op_parallelism_threads=32))

        # Add summary writers
        #merged = tf.merge_all_summaries()
        merged = tf.summary.merge_all()
        train_writer = tf.summary.FileWriter(os.path.join(LOG_DIR, 'train'),
                                  sess.graph)

        # Init variables
        init = tf.global_variables_initializer()
        sess.run(init, {is_training_pl: True})


	# COMMENT ME TO RESTORE *****************************************************************************************************************
	#saver.restore(sess, MODEL_PATH)  

	ops = {'pointclouds_pl': point_set,
	       'pointclouds_3d': pointclouds_3d,                 
	       'labels_pl': pose_set,
	       'is_training_pl': is_training_pl,
	       'pred': pred,
	       'loss': loss,
	       'train_op': train_op,
	       'merged': merged,
	       'step': batch}


	rand_size = 1200 

	for epoch in range(MAX_EPOCH):
		log_string('**** EPOCH %03d ****' % (epoch))
		sys.stdout.flush()
		arr = np.random.permutation(DataSetSize)
		images_loc, images_des, poses_train, camerapara = helper_VisualSFM_Kings.get_data(dataset_train, arr[:rand_size]) 		

		hist_points = np.zeros((len(images_loc), BLOCK_SIZE1*BLOCK_SIZE2))      
		hist_points_cum = np.zeros((len(images_loc), BLOCK_SIZE1*BLOCK_SIZE2)).astype(int)   
		print 'Loc: ', len(images_loc), rand_size	

		for i in range(len(images_loc)):
			all_points = images_loc[i] 
			all_des = images_des[i] 
			#all_points[:, 0] = all_points[:, 0]-IMZ_SZ1 # np.divide(all_points[:, 0]-IMZ_SZ1, camerapara[i][0]) 
			#all_points[:, 1] = all_points[:, 1]-IMZ_SZ2 # np.divide(all_points[:, 1]-IMZ_SZ2, camerapara[i][0]) 

			all_points[:, 2] = np.log(1+all_points[:, 3])  
			all_points[:, 3] = np.sin(all_points[:, 4]) 
			all_points[:, 4] = np.cos(all_points[:, 4])   
	
		
			idxr = np.argsort(all_points[:, 0])
			all_points = all_points[idxr, :] 
			all_des = all_des[idxr, :]
		
			# print  all_points[:10, :2], camerapara[i][0] 
			#xedges = np.linspace(-IMZ_SZ1/camerapara[i][0], IMZ_SZ1/camerapara[i][0], num=BLOCK_SIZE1+1) 
			#yedges = np.linspace(-IMZ_SZ2/camerapara[i][0], IMZ_SZ2/camerapara[i][0], num=BLOCK_SIZE2+1) 

			xedges = np.linspace(0, 2*IMZ_SZ1, num=BLOCK_SIZE1+1) 
			yedges = np.linspace(0, 2*IMZ_SZ2, num=BLOCK_SIZE2+1) 

			# print xedges, yedges
			hist_points_VL = np.histogram2d(all_points[:, 0], all_points[:, 1], bins=(xedges, yedges))
			hist_points_L = np.cumsum(np.sum(hist_points_VL[0], axis=1)).astype(int)  
			hist_points_cum[i][1:] = np.cumsum(hist_points_VL[0])[:BLOCK_SIZE1*BLOCK_SIZE2-1]
			hist_points[i] =  np.reshape(hist_points_VL[0], (1, BLOCK_SIZE1*BLOCK_SIZE2)) 
	 
			hist_points_L = hist_points_L.astype(int)
			all_points_tmp = all_points[:hist_points_L[0] , :]

			idxc = np.argsort(all_points_tmp[:, 1])
			all_points[:hist_points_L[0], :] = all_points_tmp[idxc , :]
			#print all_points[:hist_points_L[0], 0] 
		
			all_points[:hist_points_L[0], 0] = all_points[:hist_points_L[0], 0] - xedges[0]
			all_des[:hist_points_L[0], :] = all_des[idxc , :]
			#print all_points[:5, :5]  

			# print hist_points_VL[1][0], 100*all_points[:hist_points_L[0], 0], xedges[0]
			for k in range(BLOCK_SIZE1-1):
				all_points_tmp = all_points[hist_points_L[k]:hist_points_L[k+1], :]
				idxc = np.argsort(all_points_tmp[:, 1])
				all_points[hist_points_L[k]:hist_points_L[k+1], :] = all_points_tmp[idxc, :]
				all_des[hist_points_L[k]:hist_points_L[k+1], :] = all_des[hist_points_L[k]+idxc, :]  

				# print all_points[hist_points_L[k]:hist_points_L[k+1], 0], hist_points_VL[1][k]
				all_points[hist_points_L[k]:hist_points_L[k+1], 0] = all_points[hist_points_L[k]:hist_points_L[k+1], 0] - xedges[k+1]
				# print 100*all_points[hist_points_L[k]:hist_points_L[k+1], 0]
				for j in range(BLOCK_SIZE2):
					all_points[hist_points_cum[i][k*BLOCK_SIZE2+j]:hist_points_cum[i][k*BLOCK_SIZE2+j+1], 1] = all_points[hist_points_cum[i][k*BLOCK_SIZE2+j]:hist_points_cum[i][k*BLOCK_SIZE2+j+1], 1] - yedges[j]
			#print all_points[150:155, :2] 
			images_loc[i] = all_points
			images_des[i] = all_des
 
			
		#images_des_noise = []
		#for des in pool.map(add_noise, images_des, chunksize=1): 
			#images_des_noise.append(des) 

		images_train = []
		for i in range(len(images_loc)): 
			#images_train.append(np.concatenate((np.divide(images_loc[i], camerapara[i][0]), np.divide(images_des[i].astype(float), 512.0)), axis=1)) 
			images_train.append(np.concatenate((images_loc[i],images_des[i].astype(float)), axis=1)) 

		for i in range(10): 
			train_one_epoch(sess, ops, images_train, poses_train, train_writer, hist_points, hist_points_cum)

		    # Save the variables to disk.
		if epoch % 5 == 0:
			save_path = saver.save(sess, os.path.join(LOG_DIR, "model.ckpt"))
			log_string("Model saved in file: %s" % save_path)
			eval_one_epoch(sess, ops, images_train, poses_train, hist_points, hist_points_cum)


def train_one_epoch(sess, ops, images_train, poses_train, train_writer, hist_points, hist_points_cum):
	""" ops: dict mapping from string to tf ops """
	is_training = True
	file_size = len(images_train)
	point_set = np.zeros((file_size, BLOCK_SIZE1, BLOCK_SIZE2, images_train[0].shape[1]))
	pose_set = np.zeros((file_size, len(poses_train[0]))) 
	
	for i in range(file_size):
		all_points = images_train[i]
		
		no_pts, no_ftr = all_points.shape
		idx = np.random.rand(NUM_POINT,)
		idx = np.multiply(idx, hist_points[i])
		idx2 = [ii for ii, e in enumerate(idx) if e <= 10e-10]
		idx = idx.astype(int) 
		# print hist_points_cum[i], idx, no_pts 
		idx = hist_points_cum[i] + idx
		idx3 = [ii for ii, e in enumerate(idx) if e == no_pts]
		idx[idx3] = no_pts - 1 

		#print no_pts, no_ftr, idx.shape
		points = all_points[idx, :]
		points[idx2, :] = 0.0
		points[idx3, :] = 0.0
		
		point_set[i, :, :, :] = np.reshape(points, (BLOCK_SIZE1, BLOCK_SIZE2, images_train[0].shape[1]))
		# print 100*point_set[i, :2, :, :2]
		pose_set[i, :] = poses_train[i]  

	
	# point_set = np.delete(point_set, [5, 6, 7], axis=3)
	#arr = np.random.permutation(file_size) 
	#point_set = point_set[arr, :, :, :] 
	#pose_set = pose_set[arr, :]

	pointclouds_3d = point_set[:, :, :, 5:8]
	# point_set = np.delete(point_set, [5, 6, 7], axis=3)
	num_batches = file_size / BATCH_SIZE
	
	total_seen = 0
	loss_sum = 0
	
	#sess.run(tf.global_variables_initializer()) 
	for batch_idx in range(num_batches):
		start_idx = batch_idx * BATCH_SIZE
		end_idx = (batch_idx+1) * BATCH_SIZE

		# Augment batched point clouds by rotation and jittering 
		#rotated_data = provider.rotate_point_cloud(current_data[start_idx:end_idx, :, :])
		#jittered_data = provider.jitter_point_cloud(rotated_data)

		feed_dict = {ops['pointclouds_pl']: point_set[start_idx:end_idx, :, :, :],
		             ops['pointclouds_3d']: pointclouds_3d[start_idx:end_idx, :, :, :],
		             ops['labels_pl']: pose_set[start_idx:end_idx, :], 
		             ops['is_training_pl']: is_training,}

		summary, step, _, loss_val = sess.run([ops['merged'], ops['step'],
			ops['train_op'], ops['loss']], feed_dict=feed_dict)

		train_writer.add_summary(summary, step)
		# pred_val = np.argmax(pred_val, 1)

		total_seen += BATCH_SIZE
		loss_sum += loss_val
	
	log_string('mean loss: %f' % (loss_sum / float(num_batches+0.0001)))


def eval_one_epoch(sess, ops, images_train, poses_train, hist_points, hist_points_cum):
	error_cnt = 0
	is_training = False
	total_correct = 0
	total_seen = 0
	loss_sum = 0
	
	# READ IMAGES 
	#images_test, poses_test = helper.getKings(dataset_test) 
	#images_test, poses_test = helper_VisualSFM_Kings.getKings(dataset_test) 
	file_size = len(images_train) 
	num_batches = file_size / BATCH_SIZE 
	print file_size

	point_set = np.zeros((file_size, BLOCK_SIZE1, BLOCK_SIZE2, images_train[0].shape[1]))
	pointclouds_3d = np.zeros((file_size, BLOCK_SIZE1, BLOCK_SIZE2, 3))

	pose_set = np.zeros((file_size, len(poses_train[0]))) 
	pose_predict = np.zeros((file_size, len(poses_train[0]))) 
	
	for i in range(file_size):
		all_points = images_train[i]
		
		no_pts, no_ftr = all_points.shape
		idx = np.random.rand(NUM_POINT,)
		idx = np.multiply(idx, hist_points[i])
		idx2 = [ii for ii, e in enumerate(idx) if e <= 10e-10]
		idx = idx.astype(int) 
		# print hist_points_cum[i], idx, no_pts 
		idx = hist_points_cum[i] + idx
		idx3 = [ii for ii, e in enumerate(idx) if e == no_pts]
		idx[idx3] = no_pts - 1 

		points = all_points[idx, :]
		points[idx2, :] = 0.0
		points[idx3, :] = 0.0

		point_set[i, :, :, :] = np.reshape(points, (BLOCK_SIZE1, BLOCK_SIZE2, images_train[0].shape[1]))
		# print 100*point_set[i, :2, :, :2]
		pose_set[i, :] = poses_train[i]  

	for batch_idx in range(num_batches):
		start_idx = batch_idx * BATCH_SIZE
		end_idx = (batch_idx+1) * BATCH_SIZE
		cur_batch_size = end_idx - start_idx

		feed_dict = {ops['pointclouds_pl']: point_set[start_idx:end_idx, :, :, :],
		             ops['pointclouds_3d']: pointclouds_3d[start_idx:end_idx, :, :, :],
		             ops['labels_pl']: pose_set[start_idx:end_idx, :], 
		             ops['is_training_pl']: is_training,}

		loss_val, pred_val = sess.run([ops['loss'], ops['pred']],
		                          feed_dict=feed_dict)
		pose_predict[start_idx:end_idx, :] = pred_val 
		# print loss_val, pred_val 

	results = np.zeros((file_size, 2))
	#print pose_set, pose_predict
	for i in range(num_batches * BATCH_SIZE): 
		pose_x = pose_set[i, :3]
		predicted_x = pose_predict[i, :3]
		#pose_q = np.zeros(4)
		#pose_q[3] = 1; 
		pose_q = pose_set[i, 3:]
		#predicted_q = np.zeros(4)
		#predicted_q[3] = 1;
		predicted_q = pose_predict[i, 3:]
		q1 = pose_q / np.linalg.norm(pose_q)
		q2 = predicted_q / np.linalg.norm(predicted_q)
		#print 'Translation: ', pose_x, predicted_x, 'Rotation: ', q1, q2
		d = abs(np.sum(np.multiply(q1,q2)))
		theta = 2 * np.arccos(d) * 180/math.pi
		error_x = np.linalg.norm(pose_x-predicted_x)
		results[i,:] = [error_x, theta]
		print 'Iteration:  ', i, '  Error XYZ (m):  ', error_x, '  Error Q (degrees):  ', theta, 'norm:= ', np.linalg.norm(q1- q2)  
	
	#print time.time() - t
	print "Median Error: "
	print np.median(results, axis=0)
        # print np.mean(results, axis=0) 

if __name__ == "__main__":
    train()
    LOG_FOUT.close()
